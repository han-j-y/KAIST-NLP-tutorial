{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "glove.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVRiGd-8iGmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install glove-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhtX96gdJs2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GloVe 실습\n",
        "\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import pprint\n",
        "import gensim\n",
        "\n",
        "from glove import Glove\n",
        "from glove import Corpus\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFJYEsvEKAWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk  \n",
        "nltk.download('stopwords')\n",
        "\n",
        "#import nltk.downloader as api\n",
        "from nltk.corpus import stopwords  \n",
        "stops = stopwords.words('english')\n",
        "stops[:10]  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpqZp9jnKlh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define character set to delete\n",
        "\n",
        "delchars = [chr(c) for c in range(256)] \n",
        "delchars = [x for x in delchars if not x.isalnum()]\n",
        "delchars.remove(' ')\n",
        "delchars = ''.join(delchars)\n",
        "\n",
        "print (delchars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MxMDGazKyq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "corpus = api.load('text8')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-PErvBsSF2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/hanjy1777/KAIST-NLP-tutorial/raw/master/part2/shakespeare.txt\n",
        "#!wget https://github.com/hanjy1777/KAIST-NLP-tutorial/raw/master/part2/tv_text.txt\n",
        "\n",
        "filename = 'shakespeare.txt'\n",
        "#filename= 'enwiki-latest-pages-articles9.xml-p1791081p2336422.bz2'\n",
        "# Make the corpus lowercase and delete non-letter or non-digit. \n",
        "# Tokenize with space.\n",
        "\n",
        "corpus = []\n",
        "with open(filename, 'r') as datafile:\n",
        "    for line in datafile:\n",
        "        tmp = [x for x in line.lower().translate(None, delchars).split(' ') if x != '']\n",
        "        if tmp != []: corpus.append(tmp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySgZuUW0lBAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus[4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aofPSAEsLXrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the corpus dictionary and co-occurrence matrix\n",
        "corpus_model = Corpus()\n",
        "corpus_model.fit(corpus, window = 10)\n",
        "print('Dict size: %s' % len(corpus_model.dictionary))\n",
        "print('Collocations: %s' % corpus_model.matrix.nnz)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlUk9Z_-M0E-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 30\n",
        "ndim = 50\n",
        "\n",
        "glove = Glove(no_components=ndim, learning_rate=0.2) # 100 dimensional embedding\n",
        "glove.fit(corpus_model.matrix, epochs=epochs,\n",
        "          no_threads=1, verbose=True)\n",
        "glove.add_dictionary(corpus_model.dictionary)\n",
        "\n",
        "#glove.save('glove.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41sh9Im-RqPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for word in ['romeo', 'king', 'face']:\n",
        "    print(word)\n",
        "    sim_words = glove.most_similar(word, number=10)\n",
        "    for w in sim_words:\n",
        "        print (w)\n",
        "    \n",
        "    print(\"\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l0ZmEaCRwJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# randomly show the words and its closest words\n",
        "import random\n",
        "\n",
        "words = random.sample(corpus_model.dictionary.keys(),3)\n",
        "\n",
        "for word in words:\n",
        "    print(word)\n",
        "    sim_words = glove.most_similar(word, number=10)\n",
        "    for w in sim_words:\n",
        "        print (w)\n",
        "    \n",
        "    print(\"\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iUZEzR5Sai1W",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/aaronkub/machine-learning-examples/raw/master/imdb-sentiment-analysis/movie_data.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUAP_BjKatfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_train = []\n",
        "for line in open('full_train.txt', 'r'):\n",
        "    reviews_train.append(line.strip())\n",
        "    \n",
        "reviews_test = []\n",
        "for line in open('full_test.txt', 'r'):\n",
        "    reviews_test.append(line.strip())\n",
        "    \n",
        "print(reviews_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3HVQRqOa7Au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess the texts\n",
        "import re\n",
        "\n",
        "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
        "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
        "\n",
        "def preprocess_reviews(reviews):\n",
        "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
        "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
        "    \n",
        "    return reviews\n",
        "\n",
        "reviews_train_clean = preprocess_reviews(reviews_train)\n",
        "reviews_test_clean = preprocess_reviews(reviews_test)\n",
        "\n",
        "print(reviews_train_clean[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnZgggJHbA9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build dataset\n",
        "\n",
        "X = []\n",
        "X_norm = []\n",
        "for data in reviews_train_clean:\n",
        "    word_vec = np.array([0.0]*ndim)\n",
        "    word_cnt = 0\n",
        "    for word in data:\n",
        "        if word in glove.dictionary:\n",
        "            word_vec += glove.word_vectors[glove.dictionary[word],:]\n",
        "            word_cnt += 1\n",
        "    \n",
        "    X.append(word_vec)\n",
        "    X_norm.append(word_vec/word_cnt)\n",
        "    \n",
        "\n",
        "print(\"The number of train data: %d\"%len(X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Obx3MQs-bFZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = []\n",
        "for data in reviews_train_clean:\n",
        "    word_vec = np.array([0.0]*ndim)\n",
        "    #word_cnt = 0\n",
        "    for word in data:\n",
        "        if word in glove.dictionary:\n",
        "            word_vec += glove.word_vectors[glove.dictionary[word],:]\n",
        "            #word_cnt += 1\n",
        "    \n",
        "    X_test.append(word_vec)\n",
        "    #X_norm.append(word_vec/word_cnt)\n",
        "print(\"The number of test data: %d\"%len(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeP9BRIOquF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "from keras_contrib.layers import CRF\n",
        "\n",
        "# Model definition\n",
        "input = Input(shape=(MAX_LEN,))\n",
        "\n",
        "\n",
        "\n",
        "model = Embedding(input_dim=n_words+2, output_dim=EMBEDDING, # n_words + 2 (PAD & UNK)\n",
        "                  input_length=MAX_LEN, mask_zero=True)(input)  # default: 20-dim embedding\n",
        "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
        "                           recurrent_dropout=0.1))(model)  # variational biLSTM\n",
        "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
        "crf = CRF(n_tags+1)  # CRF layer, n_tags+1(PAD)\n",
        "out = crf(model)  # output\n",
        "\n",
        "model = Model(input, out)\n",
        "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDsx4UJzvuS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9QB4hXNbWD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, target, train_size = 0.75\n",
        ")\n",
        "\n",
        "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
        "    \n",
        "    lr = LogisticRegression(C=c)\n",
        "    lr.fit(X_train, y_train)\n",
        "    print (\"Accuracy for C=%s: %s\" \n",
        "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6wx3MA3brHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_model = LogisticRegression(C=0.5)\n",
        "final_model.fit(X, target)\n",
        "print (\"Final Accuracy: %s\" \n",
        "       % accuracy_score(target, final_model.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4yEMMZWfcnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = final_model.predict_proba(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th9S-KiGftlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms2hGJmIwKyY",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qsKi1Ezb-gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The most discriminating features\n",
        "\n",
        "feature_to_coef = {\n",
        "    word: coef for word, coef in zip(\n",
        "        range(100), final_model.coef_[0]\n",
        "    )\n",
        "}\n",
        "\n",
        "print (\"Best positive features\")\n",
        "\n",
        "for best_positive in sorted(\n",
        "    feature_to_coef.items(), \n",
        "    key=lambda x: x[1], \n",
        "    reverse=True)[:5]:\n",
        "    print (best_positive)\n",
        "print ()\n",
        "    \n",
        "#     ('excellent', 0.9288812418118644)\n",
        "#     ('perfect', 0.7934641227980576)\n",
        "#     ('great', 0.675040909917553)\n",
        "#     ('amazing', 0.6160398142631545)\n",
        "#     ('superb', 0.6063967799425831)\n",
        "print (\"Best negative features\")\n",
        "    \n",
        "for best_negative in sorted(\n",
        "    feature_to_coef.items(), \n",
        "    key=lambda x: x[1])[:5]:\n",
        "    print (best_negative)\n",
        "print ()\n",
        "    \n",
        "#     ('worst', -1.367978497228895)\n",
        "#     ('waste', -1.1684451288279047)\n",
        "#     ('awful', -1.0277001734353677)\n",
        "#     ('poorly', -0.8748317895742782)\n",
        "#     ('boring', -0.8587249740682945)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1KPh9XMvy59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "_,coef = zip(*feature_to_coef.items())\n",
        "plt.stem(coef)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XXV4Q4wCyKZ-",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, GRU\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RunApaeIyJyC",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3ybWn7WIyJCu",
        "colab": {}
      },
      "source": [
        "print('Build model...')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HbNL_owzyIGJ",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, EMBEDDING_DIM, input_length=max_length))\n",
        "model.add(GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX_4cfSskl2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKmyNbs6ARj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VALIDATION_SPLIT=0.2\n",
        "indices = np.arange(review_pad.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T5jeSXtlPPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Train...')\n",
        "\n",
        "model.fit(X_train_pad, target, batch_size=128, epochs=2, validation_data=(X_test_pad, target), verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}